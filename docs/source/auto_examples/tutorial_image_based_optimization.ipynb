{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nNST via image-based optimization\n================================\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch import optim\nfrom pystiche.image import show_image, write_image\nfrom pystiche.enc import vgg19_multi_layer_encoder\nfrom pystiche.ops import MSEEncodingOperator, GramOperator, MultiLayerEncodingOperator\nfrom pystiche.loss import PerceptualLoss\nfrom pystiche.demo import demo_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make this demo device-agnostic\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the encoder used to create the feature maps for the NST\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "multi_layer_encoder = vgg19_multi_layer_encoder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the content loss\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "content_layer = \"relu4_2\"\ncontent_encoder = multi_layer_encoder.extract_single_layer_encoder(content_layer)\ncontent_weight = 1e0\ncontent_loss = MSEEncodingOperator(content_encoder, score_weight=content_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the style loss\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "style_layers = (\"relu1_1\", \"relu2_1\", \"relu3_1\", \"relu4_1\", \"relu5_1\")\nstyle_weight = 1e4\n\n\ndef get_style_op(encoder, layer_weight):\n    return GramOperator(encoder, score_weight=layer_weight)\n\n\nstyle_loss = MultiLayerEncodingOperator(\n    multi_layer_encoder, style_layers, get_style_op, score_weight=style_weight,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combine the content and style loss into the optimization criterion\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "criterion = PerceptualLoss(content_loss, style_loss).to(device)\nprint(criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "load the content and style images and transfer them to the selected device\nthe images are resized, since the stylization is memory intensive\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "size = 500\nimages = demo_images()\ncontent_image = images[\"dancing\"].read(size=size, device=device)\nstyle_image = images[\"picasso\"].read(size=size, device=device)\nshow_image(content_image)\nshow_image(style_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the target images for the content and style loss\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "criterion.set_content_image(content_image)\ncriterion.set_style_image(style_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the starting point of the stylization to the content image. If you want\nto start from a white noise image instead, uncomment the line below\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_image = content_image.clone()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To avoid boilerplate code, you can achieve the same behavior with\n  :func:`~pystiche.misc.misc.get_input_image`::\n\n    from pystiche.misc import get_input_image\n\n    starting_point = \"content\"\n    input_image = get_input_image(starting_point, content_image=content_image)</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If you want to start the stylization from a white noise image instead, you\n  can use::\n\n    input_image = torch.rand_like(content_image)\n\n  or::\n\n    starting_point = \"random\"\n    input_image = get_input_image(starting_point, content_image=content_image)</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the optimizer that performs the stylization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optimizer = optim.LBFGS([input_image.requires_grad_(True)], lr=1.0, max_iter=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To avoid boilerplate code, you can achieve the same behavior with\n  :func:`~pystiche.optim.optim.default_image_optimizer`::\n\n    from pystiche.optim import default_image_optimizer\n\n    optimizer = default_image_optimizer(input_image)</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the stylization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_steps = 500\nfor step in range(1, num_steps + 1):\n\n    def closure():\n        optimizer.zero_grad()\n        loss = criterion(input_image)\n        loss.backward()\n\n        if step % 50 == 0:\n            print(f\"Step {step}\")\n            print()\n            print(loss.aggregate(1))\n            print(\"-\" * 80)\n\n        return loss\n\n    optimizer.step(closure)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To avoid boilerplate code, you can achieve the same behavior with\n  :func:`~pystiche.optim.optim.default_image_optim_loop`::\n\n    from pystiche.optim import default_image_optim_loop\n\n    default_image_optim_loop(\n        input_image, criterion, optimizer=optimizer, num_steps=num_steps\n    )\n\n  If you do not pass ``optimizer``\n  :func:`~pystiche.optim.optim.default_image_optimizer` is used.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the stylization result\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "show_image(input_image)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}