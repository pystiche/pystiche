{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nNeural Style Transfer with ``pystiche``\n=======================================\n\nThis example showcases how a basic Neural Style Transfer (NST), i.e. image-based\noptimization, could be performed with ``pystiche``.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This is an *example how to implement an NST* and **not** a\n    *tutorial on how NST works*. As such, it will not explain why a specific choice was\n    made or how a component works.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup\n-----\n\nWe start this example by importing everything we need and setting the device we will\nbe working on.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pystiche\nfrom pystiche.demo import demo_images\nfrom pystiche.enc import vgg19_multi_layer_encoder\nfrom pystiche.image import show_image, write_image\nfrom pystiche.loss import PerceptualLoss\nfrom pystiche.misc import get_device, get_input_image\nfrom pystiche.ops import (\n    FeatureReconstructionOperator,\n    GramOperator,\n    MultiLayerEncodingOperator,\n)\nfrom pystiche.optim import default_image_optim_loop\n\nprint(f\"I'm working with pystiche=={pystiche.__version__}\")\n\ndevice = get_device()\nprint(f\"I'm working with {device}\")\n\nimages = demo_images()\nimages.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``\u00ecmages.download()`` downloads **all** demo images upfront. If you only want to\n  download the images for this example remove this line. They will be downloaded at\n  runtime instead.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multi-layer Encoder\n-------------------\nThe ``content_loss`` and the ``style_loss`` operate on the encodings of an image\nrather than on the image itself. These encodings are generated by a pretrained model\ncalled encoder. Since we will be using encodings from multiple layers we load a\nmulti-layer encoder. In this example we use the ``vgg19_multi_layer_encoder`` that is\nbased on the ``VGG19`` architecture introduced by Simonyan and Zisserman\n:cite:`SZ2014` .\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "multi_layer_encoder = vgg19_multi_layer_encoder()\nprint(multi_layer_encoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perceptual Loss\n---------------\n\nThe core components of every NST are the ``content_loss`` and the ``style_loss``.\nCombined they make up the perceptual loss, i.e. the optimization criterion. In this\nexample we use the ``feature_reconstruction_loss`` introduced by Mahendran and\nVedaldi :cite:`MV2014` as ``content_loss``.\n\nFor that we first extract the ``content_encoder`` that generates encodings from the\n``content_layer``. Together with the ``content_weight`` we initialize a\n:class:`~pystiche.ops.comparison.FeatureReconstructionOperator` serving as content\nloss.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "content_layer = \"relu4_2\"\ncontent_encoder = multi_layer_encoder.extract_single_layer_encoder(content_layer)\ncontent_weight = 1e0\ncontent_loss = FeatureReconstructionOperator(\n    content_encoder, score_weight=content_weight\n)\nprint(content_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the ``gram_loss`` introduced by Gatys, Ecker, and Bethge :cite:`GEB2016` as\n``style_loss``. Other than before we use multiple ``style_layers``. The individual\n:class:`~pystiche.ops.comparison.GramOperator` s can be conveniently bundled in a\n:class:`~pystiche.ops.container.MultiLayerEncodingOperator`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "style_layers = (\"relu1_1\", \"relu2_1\", \"relu3_1\", \"relu4_1\", \"relu5_1\")\nstyle_weight = 1e3\n\n\ndef get_style_op(encoder, layer_weight):\n    return GramOperator(encoder, score_weight=layer_weight)\n\n\nstyle_loss = MultiLayerEncodingOperator(\n    multi_layer_encoder, style_layers, get_style_op, score_weight=style_weight,\n)\nprint(style_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We combine the ``content_loss`` and ``style_loss`` into a joined\n:class:`~pystiche.loss.perceptual.PerceptualLoss`, which will serve as ``criterion``\nfor the optimization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "criterion = PerceptualLoss(content_loss, style_loss).to(device)\nprint(criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Images\n------\n\nWe now load and show the images that will be used in the NST.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "size = 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>By default all images will be resized to ``size=500`` pixels on the shorter edge.\n  If you have more memory than X.X GB available you can increase this to obtain\n  higher resolution results.</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If you want to work with other images you can load them with\n  :func:`~pystiche.image.io.read_image`:\n\n  .. code-block:: python\n\n    from pystiche.image import read_image\n\n    my_image = read_image(\"my_image.jpg\", size=size, device=device)</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "content_image = images[\"bird1\"].read(size=size, device=device)\nshow_image(content_image, title=\"Content image\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "style_image = images[\"paint\"].read(size=size, device=device)\nshow_image(style_image, title=\"Style image\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neural Style Transfer\n---------------------\n\nAfter loading the images they need to be set as targets for the optimization\n``criterion``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "criterion.set_content_image(content_image)\ncriterion.set_style_image(style_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a last preliminary step we create the input image. We start from the\n``content_image`` since this way the NST converges quickly.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If you want to start from a white noise image instead use\n  ``starting_point = \"random\"`` instead:\n\n  .. code-block:: python\n\n    starting_point = \"random\"\n    input_image = get_input_image(starting_point, content_image=content_image)</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "starting_point = \"content\"\ninput_image = get_input_image(starting_point, content_image=content_image)\nshow_image(input_image, title=\"Input image\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally we run the NST with the\n:func:`~pystiche.optim.optim.default_image_optim_loop`.\nThe optimization runs on each ``level`` for ``level.num_steps``.\n\n\nIn every step perceptual loss is calculated\nwith the ``criterion`` and propagated backward to the ``input_image``. If\n``get_optimizer`` is not specified, as is the case here, the\n:func:`~pystiche.optim.optim.default_image_optimizer`, i.e.\n:class:`~torch.optim.lbfgs.LBFGS` is used.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "output_image = default_image_optim_loop(input_image, criterion, num_steps=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After the NST is complete we show the result and save it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "show_image(output_image, title=\"Output image\")\nwrite_image(output_image, \"nst_with_pystiche.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conclusion\n----------\n\nIf you started with the basic NST example without ``pystiche`` this example hopefully\nconvinced you that ``pystiche`` is helpful tool. But this was just the beginning: to\nunleash its full potential head over to the more advanced examples.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}