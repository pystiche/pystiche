.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_galleries_examples_beginner_example_nst_with_pystiche.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_galleries_examples_beginner_example_nst_with_pystiche.py:


Neural Style Transfer with ``pystiche``
=======================================

This example showcases how a basic Neural Style Transfer (NST), i.e. image-based
optimization, could be performed with ``pystiche``.

.. note::

    This is an *example how to implement an NST* and **not** a
    *tutorial on how NST works*. As such, it will not explain why a specific choice was
    made or how a component works.

Setup
-----

We start this example by importing everything we need and setting the device we will
be working on.


.. code-block:: default
   :lineno-start: 22


    import pystiche
    from pystiche.demo import demo_images
    from pystiche.enc import vgg19_multi_layer_encoder
    from pystiche.image import show_image, write_image
    from pystiche.loss import PerceptualLoss
    from pystiche.misc import get_device, get_input_image
    from pystiche.ops import (
        FeatureReconstructionOperator,
        GramOperator,
        MultiLayerEncodingOperator,
    )
    from pystiche.optim import default_image_optim_loop

    print(f"I'm working with pystiche=={pystiche.__version__}")

    device = get_device()
    print(f"I'm working with {device}")

    images = demo_images()
    images.download()






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    I'm working with pystiche==0.4.0+dev.8c738e2.dirty
    I'm working with cuda




.. note::

  ``Ã¬mages.download()`` downloads **all** demo images upfront. If you only want to
  download the images for this example remove this line. They will be downloaded at
  runtime instead.

Multi-layer Encoder
-------------------
The ``content_loss`` and the ``style_loss`` operate on the encodings of an image
rather than on the image itself. These encodings are generated by a pretrained model
called encoder. Since we will be using encodings from multiple layers we load a
multi-layer encoder. In this example we use the ``vgg19_multi_layer_encoder`` that is
based on the ``VGG19`` architecture introduced by Simonyan and Zisserman
:cite:`SZ2014` .


.. code-block:: default
   :lineno-start: 62


    multi_layer_encoder = vgg19_multi_layer_encoder()
    print(multi_layer_encoder)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    MultiLayerVGGEncoder(
      arch=vgg19, weights=torch
      (preprocessing): TorchPreprocessing(
        (0): Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
      )
      (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu1_1): ReLU()
      (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu1_2): ReLU()
      (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu2_1): ReLU()
      (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu2_2): ReLU()
      (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu3_1): ReLU()
      (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu3_2): ReLU()
      (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu3_3): ReLU()
      (conv3_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu3_4): ReLU()
      (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu4_1): ReLU()
      (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu4_2): ReLU()
      (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu4_3): ReLU()
      (conv4_4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu4_4): ReLU()
      (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu5_1): ReLU()
      (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu5_2): ReLU()
      (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu5_3): ReLU()
      (conv5_4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu5_4): ReLU()
      (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )




Perceptual Loss
---------------

The core components of every NST are the ``content_loss`` and the ``style_loss``.
Combined they make up the perceptual loss, i.e. the optimization criterion. In this
example we use the ``feature_reconstruction_loss`` introduced by Mahendran and
Vedaldi :cite:`MV2014` as ``content_loss``.

For that we first extract the ``content_encoder`` that generates encodings from the
``content_layer``. Together with the ``content_weight`` we initialize a
:class:`~pystiche.ops.comparison.FeatureReconstructionOperator` serving as content
loss.


.. code-block:: default
   :lineno-start: 80


    content_layer = "relu4_2"
    content_encoder = multi_layer_encoder.extract_single_layer_encoder(content_layer)
    content_weight = 1e0
    content_loss = FeatureReconstructionOperator(
        content_encoder, score_weight=content_weight
    )
    print(content_loss)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    FeatureReconstructionOperator(encoder=MultiLayerVGGEncoder(layer=relu4_2, arch=vgg19, weights=torch))




We use the ``gram_loss`` introduced by Gatys, Ecker, and Bethge :cite:`GEB2016` as
``style_loss``. Other than before we use multiple ``style_layers``. The individual
:class:`~pystiche.ops.comparison.GramOperator` s can be conveniently bundled in a
:class:`~pystiche.ops.container.MultiLayerEncodingOperator`.


.. code-block:: default
   :lineno-start: 95


    style_layers = ("relu1_1", "relu2_1", "relu3_1", "relu4_1", "relu5_1")
    style_weight = 1e3


    def get_style_op(encoder, layer_weight):
        return GramOperator(encoder, score_weight=layer_weight)


    style_loss = MultiLayerEncodingOperator(
        multi_layer_encoder, style_layers, get_style_op, score_weight=style_weight,
    )
    print(style_loss)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    MultiLayerEncodingOperator(
      encoder=MultiLayerVGGEncoder(arch=vgg19, weights=torch), score_weight=1e3
      (relu1_1): GramOperator(score_weight=0.2)
      (relu2_1): GramOperator(score_weight=0.2)
      (relu3_1): GramOperator(score_weight=0.2)
      (relu4_1): GramOperator(score_weight=0.2)
      (relu5_1): GramOperator(score_weight=0.2)
    )




We combine the ``content_loss`` and ``style_loss`` into a joined
:class:`~pystiche.loss.perceptual.PerceptualLoss`, which will serve as ``criterion``
for the optimization.


.. code-block:: default
   :lineno-start: 114


    criterion = PerceptualLoss(content_loss, style_loss).to(device)
    print(criterion)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    PerceptualLoss(
      (content_loss): FeatureReconstructionOperator(encoder=MultiLayerVGGEncoder(layer=relu4_2, arch=vgg19, weights=torch))
      (style_loss): MultiLayerEncodingOperator(
        encoder=MultiLayerVGGEncoder(arch=vgg19, weights=torch), score_weight=1e3
        (relu1_1): GramOperator(score_weight=0.2)
        (relu2_1): GramOperator(score_weight=0.2)
        (relu3_1): GramOperator(score_weight=0.2)
        (relu4_1): GramOperator(score_weight=0.2)
        (relu5_1): GramOperator(score_weight=0.2)
      )
    )




Images
------

We now load and show the images that will be used in the NST.


.. code-block:: default
   :lineno-start: 124


    size = 500









.. note::

  By default all images will be resized to ``size=500`` pixels on the shorter edge.
  If you have more memory than X.X GB available you can increase this to obtain
  higher resolution results.

.. note::

  If you want to work with other images you can load them with
  :func:`~pystiche.image.io.read_image`:

  .. code-block:: python

    from pystiche.image import read_image

    my_image = read_image("my_image.jpg", size=size, device=device)


.. code-block:: default
   :lineno-start: 149


    content_image = images["bird1"].read(size=size, device=device)
    show_image(content_image, title="Content image")





.. image:: /galleries/examples/beginner/images/sphx_glr_example_nst_with_pystiche_001.png
    :class: sphx-glr-single-img






.. code-block:: default
   :lineno-start: 155


    style_image = images["paint"].read(size=size, device=device)
    show_image(style_image, title="Style image")





.. image:: /galleries/examples/beginner/images/sphx_glr_example_nst_with_pystiche_002.png
    :class: sphx-glr-single-img





Neural Style Transfer
---------------------

After loading the images they need to be set as targets for the optimization
``criterion``.


.. code-block:: default
   :lineno-start: 166


    criterion.set_content_image(content_image)
    criterion.set_style_image(style_image)









As a last preliminary step we create the input image. We start from the
``content_image`` since this way the NST converges quickly.

.. note::

  If you want to start from a white noise image instead use
  ``starting_point = "random"`` instead:

  .. code-block:: python

    starting_point = "random"
    input_image = get_input_image(starting_point, content_image=content_image)


.. code-block:: default
   :lineno-start: 184


    starting_point = "content"
    input_image = get_input_image(starting_point, content_image=content_image)
    show_image(input_image, title="Input image")





.. image:: /galleries/examples/beginner/images/sphx_glr_example_nst_with_pystiche_003.png
    :class: sphx-glr-single-img





Finally we run the NST with the
:func:`~pystiche.optim.optim.default_image_optim_loop`.
The optimization runs on each ``level`` for ``level.num_steps``.


In every step perceptual loss is calculated
with the ``criterion`` and propagated backward to the ``input_image``. If
``get_optimizer`` is not specified, as is the case here, the
:func:`~pystiche.optim.optim.default_image_optimizer`, i.e.
:class:`~torch.optim.lbfgs.LBFGS` is used.


.. code-block:: default
   :lineno-start: 201


    output_image = default_image_optim_loop(input_image, criterion, num_steps=500)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    |30.04.2020 15:50:58| ################################################################################
    |30.04.2020 15:50:58| Step 50
    |30.04.2020 15:50:58| ################################################################################
    |30.04.2020 15:50:58|   content_loss: 6.808e+00
    |30.04.2020 15:50:58|   style_loss  : 1.039e+02
    |30.04.2020 15:51:05| ################################################################################
    |30.04.2020 15:51:05| Step 100
    |30.04.2020 15:51:05| ################################################################################
    |30.04.2020 15:51:05|   content_loss: 6.703e+00
    |30.04.2020 15:51:05|   style_loss  : 3.538e+01
    |30.04.2020 15:51:12| ################################################################################
    |30.04.2020 15:51:12| Step 150
    |30.04.2020 15:51:12| ################################################################################
    |30.04.2020 15:51:12|   content_loss: 6.505e+00
    |30.04.2020 15:51:12|   style_loss  : 2.201e+01
    |30.04.2020 15:51:19| ################################################################################
    |30.04.2020 15:51:19| Step 200
    |30.04.2020 15:51:19| ################################################################################
    |30.04.2020 15:51:19|   content_loss: 6.334e+00
    |30.04.2020 15:51:19|   style_loss  : 1.576e+01
    |30.04.2020 15:51:25| ################################################################################
    |30.04.2020 15:51:25| Step 250
    |30.04.2020 15:51:25| ################################################################################
    |30.04.2020 15:51:26|   content_loss: 6.173e+00
    |30.04.2020 15:51:26|   style_loss  : 1.220e+01
    |30.04.2020 15:51:32| ################################################################################
    |30.04.2020 15:51:32| Step 300
    |30.04.2020 15:51:32| ################################################################################
    |30.04.2020 15:51:32|   content_loss: 6.047e+00
    |30.04.2020 15:51:32|   style_loss  : 9.987e+00
    |30.04.2020 15:51:39| ################################################################################
    |30.04.2020 15:51:39| Step 350
    |30.04.2020 15:51:39| ################################################################################
    |30.04.2020 15:51:39|   content_loss: 5.945e+00
    |30.04.2020 15:51:39|   style_loss  : 8.287e+00
    |30.04.2020 15:51:46| ################################################################################
    |30.04.2020 15:51:46| Step 400
    |30.04.2020 15:51:46| ################################################################################
    |30.04.2020 15:51:46|   content_loss: 5.865e+00
    |30.04.2020 15:51:46|   style_loss  : 6.889e+00
    |30.04.2020 15:51:53| ################################################################################
    |30.04.2020 15:51:53| Step 450
    |30.04.2020 15:51:53| ################################################################################
    |30.04.2020 15:51:53|   content_loss: 5.793e+00
    |30.04.2020 15:51:53|   style_loss  : 5.759e+00
    |30.04.2020 15:52:00| ################################################################################
    |30.04.2020 15:52:00| Step 500
    |30.04.2020 15:52:00| ################################################################################
    |30.04.2020 15:52:00|   content_loss: 5.733e+00
    |30.04.2020 15:52:00|   style_loss  : 4.968e+00




After the NST is complete we show the result and save it.


.. code-block:: default
   :lineno-start: 207


    show_image(output_image, title="Output image")
    write_image(output_image, "nst_with_pystiche.jpg")





.. image:: /galleries/examples/beginner/images/sphx_glr_example_nst_with_pystiche_004.png
    :class: sphx-glr-single-img





Conclusion
----------

If you started with the basic NST example without ``pystiche`` this example hopefully
convinced you that ``pystiche`` is helpful tool. But this was just the beginning: to
unleash its full potential head over to the more advanced examples.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  15.914 seconds)


.. _sphx_glr_download_galleries_examples_beginner_example_nst_with_pystiche.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_nst_with_pystiche.py <example_nst_with_pystiche.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_nst_with_pystiche.ipynb <example_nst_with_pystiche.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
