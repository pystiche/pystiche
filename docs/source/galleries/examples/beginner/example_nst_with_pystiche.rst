.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_galleries_examples_beginner_example_nst_with_pystiche.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_galleries_examples_beginner_example_nst_with_pystiche.py:


Neural Style Transfer with ``pystiche``
=======================================

This example showcases how a basic Neural Style Transfer (NST), i.e. image-based
optimization, could be performed with ``pystiche``.

.. note::

    This is an *example how to implement an NST* and **not** a
    *tutorial on how NST works*. As such, it will not explain why a specific choice was
    made or how a component works.

Setup
-----

We start this example by importing everything we need and setting the device we will
be working on.


.. code-block:: default
   :lineno-start: 22


    import pystiche
    from pystiche.demo import demo_images
    from pystiche.enc import vgg19_multi_layer_encoder
    from pystiche.image import show_image, write_image
    from pystiche.loss import PerceptualLoss
    from pystiche.misc import get_device, get_input_image
    from pystiche.ops import (
        FeatureReconstructionOperator,
        GramOperator,
        MultiLayerEncodingOperator,
    )
    from pystiche.optim import default_image_optim_loop

    print(f"I'm working with pystiche=={pystiche.__version__}")

    device = get_device()
    print(f"I'm working with {device}")

    images = demo_images()






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    I'm working with pystiche==0.4.0+dev.3099d3a.dirty
    I'm working with cuda




.. note::

  During the first run all demo images are downloaded upfront. If you only want to
  download the images used in this example at runtime use

  .. code-block:: python

    images = demo_images(download=False)

Multi-layer Encoder
-------------------
The ``content_loss`` and the ``style_loss`` operate on the encodings of an image
rather than on the image itself. These encodings are generated by a pretrained model
called encoder. Since we will be using encodings from multiple layers we load a
``multi_layer_encoder`` specifically one that is based on the ``VGG19`` architecture
:cite:`SZ2014` .


.. code-block:: default
   :lineno-start: 63


    multi_layer_encoder = vgg19_multi_layer_encoder()
    print(multi_layer_encoder)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    MultiLayerVGGEncoder(
      arch=vgg19, weights=torch
      (preprocessing): TorchPreprocessing(
        (0): Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
      )
      (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu1_1): ReLU()
      (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu1_2): ReLU()
      (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu2_1): ReLU()
      (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu2_2): ReLU()
      (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu3_1): ReLU()
      (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu3_2): ReLU()
      (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu3_3): ReLU()
      (conv3_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu3_4): ReLU()
      (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu4_1): ReLU()
      (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu4_2): ReLU()
      (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu4_3): ReLU()
      (conv4_4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu4_4): ReLU()
      (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu5_1): ReLU()
      (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu5_2): ReLU()
      (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu5_3): ReLU()
      (conv5_4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu5_4): ReLU()
      (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )




Perceptual Loss
---------------

The core components of every NST are the ``content_loss`` and the ``style_loss``.
Combined they make up the perceptual loss, i.e. the optimization criterion. In this
example we use the ``feature_reconstruction_loss`` introduced by Mahendran and
Vedaldi :cite:`MV2014` as ``content_loss``.

For that we first extract the ``content_encoder`` that generates encodings from the
``content_layer``. Together with the ``content_weight`` we initialize a
:class:`~pystiche.ops.comparison.FeatureReconstructionOperator` serving as content
loss.


.. code-block:: default
   :lineno-start: 81


    content_layer = "relu4_2"
    content_encoder = multi_layer_encoder.extract_single_layer_encoder(content_layer)
    content_weight = 1e0
    content_loss = FeatureReconstructionOperator(
        content_encoder, score_weight=content_weight
    )
    print(content_loss)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    FeatureReconstructionOperator(encoder=MultiLayerVGGEncoder(layer=relu4_2, arch=vgg19, weights=torch))




We use the ``gram_loss`` introduced by Gatys, Ecker, and Bethge :cite:`GEB2016` as
``style_loss``. Other than before we use multiple ``style_layers`` so that the
individual :class:`~pystiche.ops.comparison.GramOperator` s can be conveniently
bundled in a :class:`~pystiche.ops.container.MultiLayerEncodingOperator`.


.. code-block:: default
   :lineno-start: 96


    style_layers = ("relu1_1", "relu2_1", "relu3_1", "relu4_1", "relu5_1")
    style_weight = 1e4


    def get_style_op(encoder, layer_weight):
        return GramOperator(encoder, score_weight=layer_weight)


    style_loss = MultiLayerEncodingOperator(
        multi_layer_encoder, style_layers, get_style_op, score_weight=style_weight,
    )
    print(style_loss)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    MultiLayerEncodingOperator(
      encoder=MultiLayerVGGEncoder(arch=vgg19, weights=torch), score_weight=10e3
      (relu1_1): GramOperator(score_weight=0.2)
      (relu2_1): GramOperator(score_weight=0.2)
      (relu3_1): GramOperator(score_weight=0.2)
      (relu4_1): GramOperator(score_weight=0.2)
      (relu5_1): GramOperator(score_weight=0.2)
    )




We combine the ``content_loss`` and ``style_loss`` into a joined
:class:`~pystiche.loss.perceptual.PerceptualLoss`, which will serve as ``criterion``
for the optimization.


.. code-block:: default
   :lineno-start: 115


    criterion = PerceptualLoss(content_loss, style_loss).to(device)
    print(criterion)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    PerceptualLoss(
      (content_loss): FeatureReconstructionOperator(encoder=MultiLayerVGGEncoder(layer=relu4_2, arch=vgg19, weights=torch))
      (style_loss): MultiLayerEncodingOperator(
        encoder=MultiLayerVGGEncoder(arch=vgg19, weights=torch), score_weight=10e3
        (relu1_1): GramOperator(score_weight=0.2)
        (relu2_1): GramOperator(score_weight=0.2)
        (relu3_1): GramOperator(score_weight=0.2)
        (relu4_1): GramOperator(score_weight=0.2)
        (relu5_1): GramOperator(score_weight=0.2)
      )
    )




Images
------

We now load and show the images that will be used in the NST.

.. note::

  By default all images will be resized to ``size=500`` pixels on the shorter edge.
  If you have more memory than X.X GB available you can increase this to obtain
  higher resolution results.

.. note::

  If you want to work with other images you can load them with
  :func:`~pystiche.image.io.read_image`:

  .. code-block:: python

    from pystiche.image import read_image

    my_image = read_image("my_image.jpg", size=size, device=device)


.. code-block:: default
   :lineno-start: 142


    size = 500
    content_image = images["dancing"].read(size=size, device=device)
    show_image(content_image, title="Content image")





.. image:: /galleries/examples/beginner/images/sphx_glr_example_nst_with_pystiche_001.png
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/philip/github/pystiche/pystiche/image/io.py:37: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
      plt.show()





.. code-block:: default
   :lineno-start: 149


    style_image = images["picasso"].read(size=size, device=device)
    show_image(style_image, title="Content image")





.. image:: /galleries/examples/beginner/images/sphx_glr_example_nst_with_pystiche_002.png
    :class: sphx-glr-single-img





Neural Style Transfer
---------------------

After loading the images they need to be set as targets for the optimization
``criterion``.


.. code-block:: default
   :lineno-start: 160


    criterion.set_content_image(content_image)
    criterion.set_style_image(style_image)









As a last preliminary step we create the input image. We start from the
``content_image`` since this way the NST converges quickly.

.. note::

  If you want to start from a white noise image instead use
  ``starting_point = "random"`` instead:

  .. code-block:: python

    starting_point = "random"
    input_image = get_input_image(starting_point, content_image=content_image)


.. code-block:: default
   :lineno-start: 178


    starting_point = "content"
    input_image = get_input_image(starting_point, content_image=content_image)
    show_image(input_image, title="Input image")





.. image:: /galleries/examples/beginner/images/sphx_glr_example_nst_with_pystiche_003.png
    :class: sphx-glr-single-img





Finally we run the NST and afterwards show the result and save it.


.. code-block:: default
   :lineno-start: 186


    output_image = default_image_optim_loop(input_image, criterion, num_steps=500)

    show_image(output_image, title="Output image")
    write_image(output_image, "nst_with_pystiche.jpg")




.. image:: /galleries/examples/beginner/images/sphx_glr_example_nst_with_pystiche_004.png
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    |24.04.2020 15:14:56| ################################################################################
    |24.04.2020 15:14:56| Step 50
    |24.04.2020 15:14:56| ################################################################################
    |24.04.2020 15:14:56|   content_loss: 2.492e+00
    |24.04.2020 15:14:56|   style_loss  : 8.268e+01
    |24.04.2020 15:15:00| ################################################################################
    |24.04.2020 15:15:00| Step 100
    |24.04.2020 15:15:00| ################################################################################
    |24.04.2020 15:15:00|   content_loss: 2.567e+00
    |24.04.2020 15:15:00|   style_loss  : 3.490e+01
    |24.04.2020 15:15:05| ################################################################################
    |24.04.2020 15:15:05| Step 150
    |24.04.2020 15:15:05| ################################################################################
    |24.04.2020 15:15:05|   content_loss: 2.600e+00
    |24.04.2020 15:15:05|   style_loss  : 1.943e+01
    |24.04.2020 15:15:10| ################################################################################
    |24.04.2020 15:15:10| Step 200
    |24.04.2020 15:15:10| ################################################################################
    |24.04.2020 15:15:10|   content_loss: 2.611e+00
    |24.04.2020 15:15:10|   style_loss  : 1.197e+01
    |24.04.2020 15:15:15| ################################################################################
    |24.04.2020 15:15:15| Step 250
    |24.04.2020 15:15:15| ################################################################################
    |24.04.2020 15:15:15|   content_loss: 2.608e+00
    |24.04.2020 15:15:15|   style_loss  : 8.815e+00
    |24.04.2020 15:15:21| ################################################################################
    |24.04.2020 15:15:21| Step 300
    |24.04.2020 15:15:21| ################################################################################
    |24.04.2020 15:15:21|   content_loss: 2.607e+00
    |24.04.2020 15:15:21|   style_loss  : 7.446e+00
    |24.04.2020 15:15:26| ################################################################################
    |24.04.2020 15:15:26| Step 350
    |24.04.2020 15:15:26| ################################################################################
    |24.04.2020 15:15:26|   content_loss: 2.600e+00
    |24.04.2020 15:15:26|   style_loss  : 6.713e+00
    |24.04.2020 15:15:31| ################################################################################
    |24.04.2020 15:15:31| Step 400
    |24.04.2020 15:15:31| ################################################################################
    |24.04.2020 15:15:31|   content_loss: 2.595e+00
    |24.04.2020 15:15:31|   style_loss  : 6.262e+00
    |24.04.2020 15:15:36| ################################################################################
    |24.04.2020 15:15:36| Step 450
    |24.04.2020 15:15:36| ################################################################################
    |24.04.2020 15:15:36|   content_loss: 2.591e+00
    |24.04.2020 15:15:36|   style_loss  : 5.946e+00
    |24.04.2020 15:15:40| ################################################################################
    |24.04.2020 15:15:40| Step 500
    |24.04.2020 15:15:40| ################################################################################
    |24.04.2020 15:15:40|   content_loss: 2.586e+00
    |24.04.2020 15:15:40|   style_loss  : 5.704e+00




Conclusion
----------

If you started with the basic NST example without ``pystiche`` this example hopefully
convinced you that ``pystiche`` is helpful tool. But this was just the beginning: to
unleash its full potential head over to the more advanced examples.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  55.808 seconds)


.. _sphx_glr_download_galleries_examples_beginner_example_nst_with_pystiche.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_nst_with_pystiche.py <example_nst_with_pystiche.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_nst_with_pystiche.ipynb <example_nst_with_pystiche.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
